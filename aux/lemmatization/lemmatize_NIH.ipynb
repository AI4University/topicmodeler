{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "319e2032",
   "metadata": {},
   "source": [
    "# Lemmatize NIH project abstracts using Spark NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58ccc6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "import sparknlp\n",
    "from pyspark.ml import Pipeline\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StringType\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007ee1f5",
   "metadata": {},
   "source": [
    "## 1. Read projects and abstracts. Concatenate text fields\n",
    "\n",
    "**Important:** We will use Pandas to parse the files, because pySpark does not seem to process NIH CSV files correctly when there are additional '\"' in some of the files. Pandas seems to do it OK.\n",
    "\n",
    "We will also do some basic cleanup of the text fields. This is directly done in Pandas, it may be better to do it in Spark\n",
    "\n",
    "Result is saved in a CSV file in the local folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f380bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "NIHprojects = pd.read_csv('file:///export/data_ml4ds/IntelComp/Datasets/nih/csv/20220119/projects.csv', low_memory=False)\n",
    "NIHabstracts = pd.read_csv('file:///export/data_ml4ds/IntelComp/Datasets/nih/csv/20220119/abstracts.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a7646c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "NIHprojects = NIHprojects[[\"APPLICATION_ID\", \"PROJECT_TITLE\", \"PROJECT_TERMS\", \"PHR\"]]\n",
    "NIHprojects = NIHprojects.fillna(\"\")\n",
    "NIHprojects[\"PROJECT_TERMS\"] = NIHprojects[\"PROJECT_TERMS\"].apply(lambda x: x.replace(\";\", \"; \"))\n",
    "NIHprojects[\"PHR\"] = (NIHprojects[\"PHR\"]\n",
    "                          .apply(str)\n",
    "                          .replace(\"PROJECT NARRATIVE \", \"\")\n",
    "                          .replace('\"', '')\n",
    "                          .apply(lambda x: \" \".join(x.split()))\n",
    "                     )\n",
    "NIHabstracts = NIHabstracts[[\"APPLICATION_ID\", \"ABSTRACT_TEXT\"]]\n",
    "NIHabstracts[\"ABSTRACT_TEXT\"] = (NIHabstracts[\"ABSTRACT_TEXT\"]\n",
    "                                    .apply(str)\n",
    "                                    .replace(\"PROJECT SUMMARY/ABSTRACT\", \"\")\n",
    "                                    .replace(\"PROJECT SUMMARY\", \"\")\n",
    "                                    .replace('\"', '')\n",
    "                                    .apply(lambda x: \" \".join(x.split()))\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b9ef828",
   "metadata": {},
   "outputs": [],
   "source": [
    "NIHprojects = NIHprojects.merge(NIHabstracts, how=\"inner\", on=\"APPLICATION_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1efc6a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NIHprojects[\"rawtext\"] = NIHprojects[\"PROJECT_TITLE\"] + \". \" + \\\n",
    "                         NIHprojects[\"ABSTRACT_TEXT\"] + \". \" + \\\n",
    "                         NIHprojects[\"PHR\"] + \". \" + \\\n",
    "                         NIHprojects[\"PROJECT_TERMS\"]\n",
    "NIHprojects = NIHprojects[[\"APPLICATION_ID\", \"rawtext\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ae8c46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe will be saved to temporary file\n",
    "NIHprojects.to_csv(\"./NIHrawtext.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ba78d8",
   "metadata": {},
   "source": [
    "## 2. Filter abstracts that are not in English Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d4c95a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of projects before language filtering: 2278732\n",
      "CPU times: user 29 ms, sys: 27.8 ms, total: 56.8 ms\n",
      "Wall time: 57.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NIHraw = spark.read.csv(\"file:///export/usuarios_ml4ds/jarenas/github/IntelComp/ITMT/topicmodeler/NIHrawtext.csv\", header=True)\n",
    "NIHraw = NIHraw.repartition(2000)\n",
    "print(\"Number of projects before language filtering:\", NIHraw.count())\n",
    "#NIHraw.show(n=10, truncate=120, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba2ecc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ld_wiki_tatoeba_cnn_21 download started this may take some time.\n",
      "Approximate size to download 7.1 MB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/03 21:42:29 ERROR scheduler.TaskSchedulerImpl: Lost executor 14 on node66.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/04/03 21:42:29 WARN scheduler.TaskSetManager: Lost task 24.0 in stage 10.0 (TID 2161) (node66.cluster.tsc.uc3m.es executor 14): ExecutorLostFailure (executor 14 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/04/03 21:42:29 WARN scheduler.TaskSetManager: Lost task 14.0 in stage 10.0 (TID 2151) (node66.cluster.tsc.uc3m.es executor 14): ExecutorLostFailure (executor 14 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/04/03 21:42:29 WARN scheduler.TaskSetManager: Lost task 4.0 in stage 10.0 (TID 2141) (node66.cluster.tsc.uc3m.es executor 14): ExecutorLostFailure (executor 14 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/04/03 21:42:29 WARN scheduler.TaskSetManager: Lost task 34.0 in stage 10.0 (TID 2171) (node66.cluster.tsc.uc3m.es executor 14): ExecutorLostFailure (executor 14 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/04/03 21:42:50 ERROR scheduler.TaskSchedulerImpl: Lost executor 15 on node01.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/04/03 21:42:50 WARN scheduler.TaskSetManager: Lost task 14.1 in stage 10.0 (TID 2179) (node01.cluster.tsc.uc3m.es executor 15): ExecutorLostFailure (executor 15 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/04/03 21:42:50 WARN scheduler.TaskSetManager: Lost task 4.1 in stage 10.0 (TID 2178) (node01.cluster.tsc.uc3m.es executor 15): ExecutorLostFailure (executor 15 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/04/03 21:42:50 WARN scheduler.TaskSetManager: Lost task 34.1 in stage 10.0 (TID 2177) (node01.cluster.tsc.uc3m.es executor 15): ExecutorLostFailure (executor 15 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/04/03 21:42:50 WARN scheduler.TaskSetManager: Lost task 24.1 in stage 10.0 (TID 2180) (node01.cluster.tsc.uc3m.es executor 15): ExecutorLostFailure (executor 15 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/04/03 21:43:14 ERROR scheduler.TaskSchedulerImpl: Lost executor 16 on node02.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/04/03 21:43:14 WARN scheduler.TaskSetManager: Lost task 34.2 in stage 10.0 (TID 2182) (node02.cluster.tsc.uc3m.es executor 16): ExecutorLostFailure (executor 16 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/04/03 21:43:14 WARN scheduler.TaskSetManager: Lost task 24.2 in stage 10.0 (TID 2181) (node02.cluster.tsc.uc3m.es executor 16): ExecutorLostFailure (executor 16 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/04/03 21:43:14 WARN scheduler.TaskSetManager: Lost task 14.2 in stage 10.0 (TID 2184) (node02.cluster.tsc.uc3m.es executor 16): ExecutorLostFailure (executor 16 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "22/04/03 21:43:14 WARN scheduler.TaskSetManager: Lost task 4.2 in stage 10.0 (TID 2183) (node02.cluster.tsc.uc3m.es executor 16): ExecutorLostFailure (executor 16 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "[Stage 12:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of projects in English: 2231208\n",
      "CPU times: user 329 ms, sys: 36.1 ms, total: 365 ms\n",
      "Wall time: 31min 53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Pipeline for language detection\n",
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"rawtext\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "languageDetector = LanguageDetectorDL.pretrained() \\\n",
    "    .setInputCols(\"document\") \\\n",
    "    .setOutputCol(\"language\")\n",
    "\n",
    "pipeline = Pipeline() \\\n",
    "    .setStages([\n",
    "      documentAssembler,\n",
    "      languageDetector\n",
    "    ])\n",
    "\n",
    "#Apply language detection pipeline\n",
    "NIHraw = pipeline.fit(NIHraw).transform(NIHraw)\n",
    "NIHraw = (\n",
    "    NIHraw.filter(F.col(\"language.result\")[0]==\"en\")\n",
    "    .drop(\"language\")\n",
    ")\n",
    "\n",
    "print('Number of projects in English:', NIHraw.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4d59da",
   "metadata": {},
   "source": [
    "## 3. Define and Run Lemmatization Pipeline\n",
    "\n",
    "   - We work on documents created in Subsection 2\n",
    "   - Sentence Detection and Tokenizer applied to detect tokens\n",
    "   - Lemmatization is carried out\n",
    "   - Stopwords are applied\n",
    "   - Punctuation symbols are removed\n",
    "   - Result is converted back from Spark NLP annotations to string format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eecf0f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[ | ]lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[ / ]Download done! Loading the resource.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 14:==============>                                          (3 + 1) / 12]\r",
      "\r",
      "[Stage 14:===================>                                     (4 + 0) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \\ ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 14:===================================================>    (11 + 1) / 12]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------------------------------------------------------------------------------------------------------------\n",
      " APPLICATION_ID | 6409710                                                                                                                  \n",
      " lemmas         | arginine butyrate therapyleg ulcer sickle cell dise sickle cell disease thalassemias result genetic defect adult glob... \n",
      "-RECORD 1----------------------------------------------------------------------------------------------------------------------------------\n",
      " APPLICATION_ID | 6125921                                                                                                                  \n",
      " lemmas         | mechanical factors energy loss myocardial regions research attempt restore energetic hemodynamic efficiency reperfuse... \n",
      "-RECORD 2----------------------------------------------------------------------------------------------------------------------------------\n",
      " APPLICATION_ID | 6360885                                                                                                                  \n",
      " lemmas         | tissue pulsatility imaging cancer detection nan neoplasm cancer diagnosis biomechanics bioimaging biomedical image       \n",
      "-RECORD 3----------------------------------------------------------------------------------------------------------------------------------\n",
      " APPLICATION_ID | 6173944                                                                                                                  \n",
      " lemmas         | regulation cell death chicken bursal lymphoma proposal investigate function nr13 new member bcl2 family cell death an... \n",
      "-RECORD 4----------------------------------------------------------------------------------------------------------------------------------\n",
      " APPLICATION_ID | 6328021                                                                                                                  \n",
      " lemmas         | two dimensional ir spectroscopy designed pentapeptide form twodimensional 2d vibrational spectroscopy use examine str... \n",
      "-RECORD 5----------------------------------------------------------------------------------------------------------------------------------\n",
      " APPLICATION_ID | 6178365                                                                                                                  \n",
      " lemmas         | bladder cancer case control study arsenic water application propose populationbased casecontrol study man woman exami... \n",
      "-RECORD 6----------------------------------------------------------------------------------------------------------------------------------\n",
      " APPLICATION_ID | 6359639                                                                                                                  \n",
      " lemmas         | coreanalytic analytic core consist two component facshsc histology facshsc component isolate immunophenotypic subpopu... \n",
      "-RECORD 7----------------------------------------------------------------------------------------------------------------------------------\n",
      " APPLICATION_ID | 6335657                                                                                                                  \n",
      " lemmas         | measuring mental health outcomes fairly proposal request fund convene national research development conference topic ... \n",
      "-RECORD 8----------------------------------------------------------------------------------------------------------------------------------\n",
      " APPLICATION_ID | 6137368                                                                                                                  \n",
      " lemmas         | cell surface structure transformations overall aim understand molecular basis cell matrix adhesion effect cell struct... \n",
      "-RECORD 9----------------------------------------------------------------------------------------------------------------------------------\n",
      " APPLICATION_ID | 6305241                                                                                                                  \n",
      " lemmas         | effects exercise protein metabolism humans previous fund period project establish muscle protein synthesis stimulate ... \n",
      "only showing top 10 rows\n",
      "\n",
      "CPU times: user 409 ms, sys: 41.6 ms, total: 451 ms\n",
      "Wall time: 30min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "#Next, we carry out the lemmatization pipeline\n",
    "\n",
    "sentenceDetector = SentenceDetector() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "lemmatizer = LemmatizerModel.pretrained() \\\n",
    "    .setInputCols([\"token\"]) \\\n",
    "    .setOutputCol(\"lemma\")\n",
    "\n",
    "stopWords = StopWordsCleaner() \\\n",
    "    .setInputCols([\"lemma\"]) \\\n",
    "    .setOutputCol(\"cleanlemma\")\n",
    "\n",
    "normalizer = Normalizer() \\\n",
    "    .setInputCols([\"cleanlemma\"]) \\\n",
    "    .setOutputCol(\"normalizedlemma\") \\\n",
    "    .setLowercase(True) \\\n",
    "    .setCleanupPatterns([\"\"\"[^\\w\\d\\s]\"\"\"])\n",
    "\n",
    "finisher = Finisher() \\\n",
    "     .setInputCols(['normalizedlemma'])\n",
    "\n",
    "pipeline = Pipeline() \\\n",
    "    .setStages([\n",
    "      sentenceDetector,\n",
    "      tokenizer,\n",
    "      lemmatizer,\n",
    "      stopWords,\n",
    "      normalizer,\n",
    "      finisher\n",
    "])\n",
    "\n",
    "#We apply pipeline and recover lemmas as string\n",
    "NIHraw = pipeline.fit(NIHraw).transform(NIHraw)\n",
    "\n",
    "udf_back2str = F.udf(lambda x:' '.join(list(x)), StringType() )\n",
    "NIHraw = (\n",
    "    NIHraw.withColumn(\"lemmas\",udf_back2str(F.col(\"finished_normalizedlemma\")))\n",
    "    .drop(\"rawtext\")\n",
    "    .drop(\"finished_normalizedlemma\")\n",
    ")\n",
    "\n",
    "#Show results of validation for n papers\n",
    "NIHraw.show(n=10, truncate=120, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f63e174",
   "metadata": {},
   "source": [
    "## 4. Save a table with `APPLICATION_ID` and `lemmas` to HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4c5b911",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.01 s, sys: 128 ms, total: 1.14 s\n",
      "Wall time: 46min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Save calculated lemmas to HDFS\n",
    "dir_parquet = Path(\"/export/ml4ds/IntelComp/Datalake/NIH/20220119\")\n",
    "\n",
    "NIHraw.coalesce(1000).write.parquet(\n",
    "    dir_parquet.joinpath(f\"projects_NLP.parquet\").as_posix(),\n",
    "    mode=\"overwrite\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb1450a",
   "metadata": {},
   "source": [
    "## 5. Delete temporary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78fc54f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file deleted\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "file = \"./NIHrawtext.csv\"\n",
    "\n",
    "if(os.path.exists(file) and os.path.isfile(file)):\n",
    "    os.remove(file)\n",
    "    print(\"file deleted\")\n",
    "else:\n",
    "    print(\"file not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c19228",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
