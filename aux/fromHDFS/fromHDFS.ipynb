{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ae6dcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Temporary routine for generation of datasets\n",
    "for demonstration purposes\n",
    "\n",
    "It is a \"Fake Data Mediator\" for use with the first\n",
    "version of the Interactive Topic Model Trainer\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from langdetect import detect\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eab3b54-8122-416f-99d0-783c1f723971",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This variables will be passed as parameters via command line\n",
    "\n",
    "#parquet_table = '/export/ml4ds/IntelComp/Datalake/SemanticScholar/20220201/papers.parquet'\n",
    "#selectFields = 'title, paperAbstract, doi, year, fieldsOfStudy'\n",
    "#filterCondition = \"array_contains(fieldsOfStudy, 'Computer Science')\"\n",
    "#path_dataset = \"/export/usuarios_ml4ds/jarenas/github/IntelComp/ITMT/topicmodeler/fromHDFS/S2CS\"\n",
    "\n",
    "parquet_table = '/export/ml4ds/IntelComp/Datalake/CORDIS/20220221/new_parquet/projects.parquet'\n",
    "selectFields = 'title, objective, startDate, ecMaxContribution, euroSciVocCode'\n",
    "filterCondition = ''\n",
    "path_dataset = \"/export/usuarios_ml4ds/jarenas/github/IntelComp/ITMT/topicmodeler/fromHDFS/CORDIS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0269e65c-b3d5-4a2c-99c8-f981d2b2c350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/21 19:12:02 WARN conf.HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "22/05/21 19:12:02 WARN conf.HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "22/05/21 19:12:04 WARN metastore.ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
      "22/05/21 19:12:04 WARN metastore.ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore jarenas@192.168.148.225\n",
      "22/05/21 19:12:05 WARN metastore.ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n",
      "22/05/21 19:12:05 WARN metastore.ObjectStore: Failed to get database parquet, returning NoSuchObjectException\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# We read the table with the output of NLP processes and identify id field \n",
    "lemmas_table = parquet_table.split('.parquet')[0] + '_NLP.parquet'\n",
    "lemmas_df = spark.sql(f\"SELECT * FROM parquet.`{lemmas_table}`\")\n",
    "# Obtain the name of the column that has to be used as the main identifier for the corpus\n",
    "id_fld = [el for el in lemmas_df.columns if el in ['projectID', 'id', 'appln_id']][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4205c000-4ef8-4274-9452-e853cb354aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/21 19:12:18 WARN metastore.ObjectStore: Failed to get database parquet, returning NoSuchObjectException\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# We read the main table including selected fields and the identifier\n",
    "flds = [el.strip() for el in selectFields.split(',')]\n",
    "query = \"SELECT \" + id_fld + \" AS id, \" + (\",\").join(flds) + \\\n",
    "                \" FROM parquet.`\" + parquet_table + \"`\"\n",
    "\n",
    "# Add filtering condition to SELECT clause if necessary\n",
    "if len(filterCondition.strip()):\n",
    "    query += \" WHERE \" + filterCondition\n",
    "dataset = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24739c70-5a1e-4c03-b027-a9969261b86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:===================================================>   (186 + 8) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in dataset: 61163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Join tables\n",
    "lemmas_df = lemmas_df.withColumnRenamed(id_fld,\"id\")\n",
    "dataset = (dataset.join(lemmas_df, dataset.id ==  lemmas_df.id, \"left\")\n",
    "                      .drop(lemmas_df.id)\n",
    "                )\n",
    "\n",
    "print('Number of documents in dataset:', dataset.count())\n",
    "#dataset.show(n=10, truncate=120, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a32cbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Save dataset\n",
    "dataset.write.parquet(f\"file://{path_dataset}\",\n",
    "    mode=\"overwrite\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9998cbf-535c-48ec-9385-554c1e1a5781",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
