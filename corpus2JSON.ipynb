{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ae6dcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Mar 06 2022\n",
    "@author: Jerónimo Arenas García\n",
    "\n",
    "Temporary routine for generation of JSON files\n",
    "simulating the creation of files required for the\n",
    "BI tool\n",
    "\n",
    "If other datasets want to be ingested, we need to\n",
    "1) Change the SELECT statement accordingly\n",
    "2) Change the fields as necessary\n",
    "3) Change the name of the folder where the JSON will be save\n",
    "\"\"\"\n",
    "\n",
    "import TMinferencer\n",
    "import io\n",
    "from langdetect import detect\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import array_contains, concat_ws, col, udf\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dc462e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.addPyFile(\"TMinferencer.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d25510a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/06 22:03:50 WARN conf.HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "22/03/06 22:03:50 WARN conf.HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "22/03/06 22:03:52 WARN metastore.ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
      "22/03/06 22:03:52 WARN metastore.ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore jarenas@192.168.148.225\n",
      "22/03/06 22:03:52 WARN metastore.ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n",
      "22/03/06 22:03:52 WARN metastore.ObjectStore: Failed to get database parquet, returning NoSuchObjectException\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Read subtable from parquet file\n",
    "S2papers = spark.sql(\"SELECT id, year, venue, title, paperAbstract FROM parquet.`/export/ml4ds/IntelComp/Datalake/SemanticScholar/20220201/papers.parquet` where array_contains(fieldsOfStudy, 'Computer Science')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fcf8301",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate text fields to lemmatize\n",
    "S2papers = (\n",
    "    S2papers.withColumn(\"rawtext\",concat_ws('. ', \"title\", \"paperAbstract\"))\n",
    "    .drop(\"paperAbstract\")\n",
    ")\n",
    "\n",
    "def my_detect(rawt):\n",
    "    try:\n",
    "        return detect(rawt)\n",
    "    except:\n",
    "        return \"na\"\n",
    "\n",
    "udf_detect = udf(lambda x:my_detect(x), StringType() )\n",
    "S2papers = S2papers.withColumn(\"language\",udf_detect(col(\"rawtext\")))\n",
    "S2papers = (\n",
    "    S2papers.filter(col(\"language\")==\"en\")\n",
    "    .drop(\"language\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55a9a7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TMinference(rawt):\n",
    "    thetas = TMinferencer.main(io.StringIO(rawt.replace(\"\\n\", \" \")))\n",
    "    return \" \".join(\"t\"+str(el[0])+\"|\"+str(round(1000*el[1])) for el in thetas[0].items())\n",
    "udf_TMinference = udf(lambda x:TMinference(x), StringType() )\n",
    "\n",
    "S2papers = S2papers.withColumn(\"TM40\",udf_TMinference(col(\"rawtext\")))\n",
    "S2papers = S2papers.drop(\"rawtext\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a32cbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Save corpus\n",
    "S2papers.repartition(100).write.json(f\"file:///export/usuarios_ml4ds/jarenas/github/IntelComp/ITMT/topicmodeler/S2CS.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8788a6f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
