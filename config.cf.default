# Specify format for the log outputs
[logformat]
filename = msgs.log
datefmt = %%Y-%%d-%%m %%H:%%M:%%S
file_format= %%(asctime)s | %%(levelname)-8s | %%(message)s
file_level = INFO
cons_level = DEBUG
cons_format = %%(levelname)-8s | %%(message)s

[Spark]
script_spark = /export/usuarios_ml4ds/jarenas/script-spark/script-spark
token_spark = /export/usuarios_ml4ds/jarenas/script-spark/tokencluster.json

[HDFS]
#This paths are specific to UC3M deployment
Semantic Scholar = /export/ml4ds/IntelComp/Datalake/SemanticScholar/20220201/papers.parquet
PATSTAT = /export/ml4ds/IntelComp/Datalake/PATSTAT/2021_Autumn/patstat_appln.parquet
CORDIS = /export/ml4ds/IntelComp/Datalake/CORDIS/20220221/new_parquet/projects.parquet

[TM]
#Default setting for number of topics
ntopics=25

[MalletTM]
#Minimum number of words to keep document in corpus
min_lemas = 15
#Remove words with less than no_below occurrences
no_below=10
#Remove words appearing in more than a given percentage of documents
no_above=0.6
#Maximum number of words in vocabulary
keep_n=500000
#Regular expression for token identification
token_regexp=[\p{L}\p{N}][\p{L}\p{N}\p{P}]*\p{L}
#Path to mallet binary
mallet_path=./mallet-2.0.8/bin/mallet
#default STWs
default_stw_file=./aux/stop-words-english5.txt
#default equivalencies
default_eq_file=./aux/equivalents.txt

#Settings for mallet training and doctopics postprocessing
alpha=5
optimize_interval=10
num_threads=4
num_iterations=1000
doc_topic_thr=0
thetas_thr=3e-3
num_iterations_inf=100




[TMold]
pathlabeling=./topicmodeler/NETL-topic-labeler/

[TMedit]
n_palabras=20
round_size=6
NETLworkers=3
LDAvis_ndocs=25000
LDAvis_njobs=15